{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numba.readthedocs.io/en/stable/cuda/memory.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f6be04b29e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ary = np.arange(10)\n",
    "d_ary = cuda.to_device(ary)\n",
    "d_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f6bcc12c970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = cuda.stream()\n",
    "d_ary = cuda.to_device(ary, stream=stream)\n",
    "d_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hary = d_ary.copy_to_host()\n",
    "hary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ary = np.empty(shape=d_ary.shape, dtype=d_ary.dtype)\n",
    "d_ary.copy_to_host(ary)\n",
    "ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hary = d_ary.copy_to_host(stream=stream)\n",
    "hary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 100 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  6,  8,  8,  9, 10, 11, 12, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def my_kernel(arr):\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] += 1\n",
    "\n",
    "arr = np.arange(1000)\n",
    "\n",
    "d_arr = cuda.to_device(arr)\n",
    "\n",
    "my_kernel[100, 100](d_arr)\n",
    "\n",
    "result_array = d_arr.copy_to_host()\n",
    "\n",
    "result_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_arr = d_arr.reshape(20, 50, order='F')\n",
    "d_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def kernel_func(x):\n",
    "   dyn_arr = cuda.shared.array(0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "kernel_func[32, 32, 0, 128](arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.140000\n",
      "1078523331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def f():\n",
    "   f32_arr = cuda.shared.array(0, dtype=np.float32)\n",
    "   i32_arr = cuda.shared.array(0, dtype=np.int32)\n",
    "   f32_arr[0] = 3.14\n",
    "   print(f32_arr[0])\n",
    "   print(i32_arr[0])\n",
    "\n",
    "f[1, 1, 0, 4]()\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.140000\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def f_with_view():\n",
    "   f32_arr = cuda.shared.array(0, dtype=np.float32)\n",
    "   i32_arr = cuda.shared.array(0, dtype=np.int32)[1:] # 1 int32 = 4 bytes\n",
    "   f32_arr[0] = 3.14\n",
    "   i32_arr[0] = 1\n",
    "   print(f32_arr[0])\n",
    "   print(i32_arr[0])\n",
    "\n",
    "f_with_view[1, 1, 0, 8]()\n",
    "cuda.synchronize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuNumba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
