{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numba.readthedocs.io/en/stable/cuda/cooperative_groups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, int32\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sig = (int32[:,::1],)\n",
    "\n",
    "\n",
    "@cuda.jit(sig)\n",
    "\n",
    "def sequential_rows(M):\n",
    "\n",
    "    col = cuda.grid(1)\n",
    "\n",
    "    g = cuda.cg.this_grid()\n",
    "\n",
    "\n",
    "    rows = M.shape[0]\n",
    "\n",
    "    cols = M.shape[1]\n",
    "\n",
    "\n",
    "    for row in range(1, rows):\n",
    "\n",
    "        opposite = cols - col - 1\n",
    "\n",
    "        # Each row's elements are one greater than the previous row\n",
    "\n",
    "        M[row, col] = M[row - 1, opposite] + 1\n",
    "\n",
    "        # Wait until all threads have written their column element,\n",
    "\n",
    "        # and that the write is visible to all other threads\n",
    "\n",
    "        g.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty input data\n",
    "\n",
    "A = np.zeros((1024, 1024), dtype=np.int32)\n",
    "\n",
    "# A somewhat arbitrary choice (one warp), but generally smaller block sizes\n",
    "\n",
    "# allow more blocks to be launched (noting that other limitations on\n",
    "\n",
    "# occupancy apply such as shared memory size)\n",
    "\n",
    "blockdim = 32\n",
    "\n",
    "griddim = A.shape[1] // blockdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0    0]\n",
      " [   1    1    1 ...    1    1    1]\n",
      " [   2    2    2 ...    2    2    2]\n",
      " ...\n",
      " [1021 1021 1021 ... 1021 1021 1021]\n",
      " [1022 1022 1022 ... 1022 1022 1022]\n",
      " [1023 1023 1023 ... 1023 1023 1023]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago.esterci/.conda/envs/CuNumba/lib/python3.10/site-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "# Kernel launch - this is implicitly a cooperative launch\n",
    "\n",
    "sequential_rows[griddim, blockdim](A)\n",
    "\n",
    "\n",
    "# What do the results look like?\n",
    "\n",
    "# print(A)\n",
    "\n",
    "#\n",
    "\n",
    "# [[   0    0    0 ...    0    0    0]\n",
    "\n",
    "#  [   1    1    1 ...    1    1    1]\n",
    "\n",
    "#  [   2    2    2 ...    2    2    2]\n",
    "\n",
    "#  ...\n",
    "\n",
    "#  [1021 1021 1021 ... 1021 1021 1021]\n",
    "\n",
    "#  [1022 1022 1022 ... 1022 1022 1022]\n",
    "\n",
    "#  [1023 1023 1023 ... 1023 1023 1023]]\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    }
   ],
   "source": [
    "overload = sequential_rows.overloads[(int32[:,::1],)]\n",
    "max_blocks = overload.max_cooperative_grid_blocks(blockdim)\n",
    "print(max_blocks)\n",
    "# 1152 (e.g. on Quadro RTX 8000 with Numba 0.52.1 and CUDA 11.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuNumba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
